{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a635ebef-9106-4cca-b980-c46ce4315b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching dataset...\n",
      "Dataset downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Data Ingestion and Initialization\n",
    "Run this cell to import the necessary libraries and set your configuration variables.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# --- CONFIGURATION & FETCH ---\n",
    "# Public URL for the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "FILE_PATH = 'titanic_sample.csv'\n",
    "\n",
    "# Fetch the file locally so our load_data function can process it\n",
    "if not os.path.exists(FILE_PATH):\n",
    "    print(\"Fetching dataset...\")\n",
    "    urllib.request.urlretrieve(url, FILE_PATH)\n",
    "    print(\"Dataset downloaded successfully!\")\n",
    "\n",
    "# Choose your missing value strategy: 'drop', 'fill_mean_mode', or 'none'\n",
    "MISSING_STRATEGY = 'fill_mean_mode'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9582f7af-792d-47d0-9f1e-33f3ecb7454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded titanic_sample.csv with shape (891, 12)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"1. Data Loading\n",
    "This function detects the file extension and loads the data accordingly. It uses Python's built-in sniffer for text files to auto-detect delimiters.\"\"\"\n",
    "\n",
    "def load_data(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} was not found.\")\n",
    "        \n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    \n",
    "    try:\n",
    "        if ext == '.csv':\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif ext == '.json':\n",
    "            df = pd.read_json(file_path)\n",
    "        elif ext == '.txt':\n",
    "            # sep=None and engine='python' allow pandas to automatically sniff the delimiter\n",
    "            df = pd.read_csv(file_path, sep=None, engine='python')\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {ext}\")\n",
    "        \n",
    "        print(f\"Successfully loaded {file_path} with shape {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "df = load_data(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caeb1129-c308-4daa-baf9-bcfa70dd0a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns normalized.\n",
      "Total missing values found: 866\n",
      "Filled missing values (mean for numerical, mode for categorical).\n"
     ]
    }
   ],
   "source": [
    "\"\"\"2. Normalization & Cleaning\n",
    "Here we standardize the column names to `snake_case` and apply our chosen missing value strategy.\"\"\"\n",
    "\n",
    "def normalize_columns(df):\n",
    "    \"\"\"Converts column names to lowercase, replaces spaces with underscores, and strips whitespace.\"\"\"\n",
    "    df.columns = (df.columns\n",
    "                  .str.strip()\n",
    "                  .str.lower()\n",
    "                  .str.replace(' ', '_')\n",
    "                  .str.replace(r'[^\\w\\s]', '', regex=True)) # Removes special characters\n",
    "    print(\"Columns normalized.\")\n",
    "    return df\n",
    "\n",
    "def handle_missing_values(df, strategy='none'):\n",
    "    \"\"\"Handles missing values based on the selected strategy.\"\"\"\n",
    "    missing_count = df.isna().sum().sum()\n",
    "    print(f\"Total missing values found: {missing_count}\")\n",
    "    \n",
    "    if strategy == 'drop':\n",
    "        df = df.dropna()\n",
    "        print(\"Dropped rows with missing values.\")\n",
    "    elif strategy == 'fill_mean_mode':\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                df[col] = df[col].fillna(df[col].mean())\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else \"Unknown\")\n",
    "        print(\"Filled missing values (mean for numerical, mode for categorical).\")\n",
    "    elif strategy == 'none':\n",
    "        print(\"Missing values left untouched.\")\n",
    "    else:\n",
    "        print(f\"Unrecognized strategy '{strategy}'. Missing values left untouched.\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "if df is not None:\n",
    "    df = normalize_columns(df)\n",
    "    df = handle_missing_values(df, strategy=MISSING_STRATEGY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba189d0-3b6d-4442-9131-7b9dc146cef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Preview (head) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived  pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                name     sex   age  sibsp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   parch            ticket     fare    cabin embarked  \n",
       "0      0         A/5 21171   7.2500  B96 B98        S  \n",
       "1      0          PC 17599  71.2833      C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  B96 B98        S  \n",
       "3      0            113803  53.1000     C123        S  \n",
       "4      0            373450   8.0500  B96 B98        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistical Summary (describe) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>691</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        passengerid    survived      pclass                     name   sex  \\\n",
       "count    891.000000  891.000000  891.000000                      891   891   \n",
       "unique          NaN         NaN         NaN                      891     2   \n",
       "top             NaN         NaN         NaN  Braund, Mr. Owen Harris  male   \n",
       "freq            NaN         NaN         NaN                        1   577   \n",
       "mean     446.000000    0.383838    2.308642                      NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                      NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                      NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                      NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                      NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                      NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                      NaN   NaN   \n",
       "\n",
       "               age       sibsp       parch  ticket        fare    cabin  \\\n",
       "count   891.000000  891.000000  891.000000     891  891.000000      891   \n",
       "unique         NaN         NaN         NaN     681         NaN      147   \n",
       "top            NaN         NaN         NaN  347082         NaN  B96 B98   \n",
       "freq           NaN         NaN         NaN       7         NaN      691   \n",
       "mean     29.699118    0.523008    0.381594     NaN   32.204208      NaN   \n",
       "std      13.002015    1.102743    0.806057     NaN   49.693429      NaN   \n",
       "min       0.420000    0.000000    0.000000     NaN    0.000000      NaN   \n",
       "25%      22.000000    0.000000    0.000000     NaN    7.910400      NaN   \n",
       "50%      29.699118    0.000000    0.000000     NaN   14.454200      NaN   \n",
       "75%      35.000000    1.000000    0.000000     NaN   31.000000      NaN   \n",
       "max      80.000000    8.000000    6.000000     NaN  512.329200      NaN   \n",
       "\n",
       "       embarked  \n",
       "count       891  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        646  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Categorical Distributions (value_counts) ---\n",
      "\n",
      "Value counts for 'name':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name\n",
       "Braund, Mr. Owen Harris             1\n",
       "Boulos, Mr. Hanna                   1\n",
       "Frolicher-Stehli, Mr. Maxmillian    1\n",
       "Gilinski, Mr. Eliezer               1\n",
       "Murdlin, Mr. Joseph                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'sex':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sex\n",
       "male      577\n",
       "female    314\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'ticket':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ticket\n",
       "347082      7\n",
       "CA. 2343    7\n",
       "1601        7\n",
       "3101295     6\n",
       "CA 2144     6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'cabin':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cabin\n",
       "B96 B98        691\n",
       "G6               4\n",
       "C23 C25 C27      4\n",
       "C22 C26          3\n",
       "F33              3\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'embarked':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "embarked\n",
       "S    646\n",
       "C    168\n",
       "Q     77\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"3. Exploratory Data Analysis (EDA)\n",
    "Running basic statistical summaries and distributions to understand the dataset.\"\"\"\n",
    "\n",
    "def run_simple_eda(df):\n",
    "    print(\"\\n--- Data Preview (head) ---\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\n--- Statistical Summary (describe) ---\")\n",
    "    display(df.describe(include='all'))\n",
    "    \n",
    "    print(\"\\n--- Categorical Distributions (value_counts) ---\")\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        for col in categorical_cols:\n",
    "            print(f\"\\nValue counts for '{col}':\")\n",
    "            # Show top 5 categories to keep output clean\n",
    "            display(df[col].value_counts().head(5)) \n",
    "    else:\n",
    "        print(\"No categorical columns found.\")\n",
    "\n",
    "if df is not None:\n",
    "    run_simple_eda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e00204a-7cbd-4ac8-a6ef-cf97717c67d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline complete. Cleaned data saved to 'cleaned_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"4. Export\n",
    "Saving the finalized, cleaned dataset to a new CSV.\"\"\"\n",
    "\n",
    "if df is not None:\n",
    "    output_filename = 'cleaned_data.csv'\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nPipeline complete. Cleaned data saved to '{output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8339a70-ac17-447c-a51d-629216e4ec45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
